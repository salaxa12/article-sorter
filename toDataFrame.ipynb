{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# example_sent = \"\"\"This is a sample sentence,\n",
    "#                   showing off the stop words filtration.\"\"\"\n",
    "  \n",
    "  \n",
    "# word_tokens = word_tokenize(example_sent)\n",
    "  \n",
    "# filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "  \n",
    "# filtered_sentence = []\n",
    "  \n",
    "# for w in word_tokens:\n",
    "#     if w not in stop_words:\n",
    "#         filtered_sentence.append(w)\n",
    "  \n",
    "# print(word_tokens)\n",
    "# print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanArticle(file2read):\n",
    "\n",
    "    stop_words = set(stopwords.words('english') + list(string.punctuation)) # decleare extra words and punctioations\n",
    "\n",
    "    article = '' # declare the returning variable\n",
    "    customExtras = [\"\\n\", \"’\", \"“\", \"”\", \"'\", \"`\", \"-\", \"[\", \"]\", \"»\"] # declare extra chars of article which are not included in the previous packages \n",
    "    \n",
    "    def listToString(s): #function that converts arr of strings into one string (used later)\n",
    "        str1 = \" \"\n",
    "        return (str1.join(s))\n",
    "\n",
    "\n",
    "    for i in customExtras: # remove extra chars in article\n",
    "        file2read = file2read.replace(i, \" \")\n",
    "\n",
    "    \n",
    "    word_tokens= word_tokenize(file2read.lower()) #converts arcivle into array of words\n",
    "    # print(word_tokens)\n",
    "\n",
    "\n",
    "    filtered_file2read =[] #empty array of clean words\n",
    "\n",
    "    for w in word_tokens: # check if word from article is the extra , if not assign the word in the clean words array\n",
    "        if w not in stop_words and w.isalpha() == True:\n",
    "            filtered_file2read.append(w)\n",
    "\n",
    "    # print(filtered_file2read)\n",
    "\n",
    "\n",
    "    article = listToString(filtered_file2read)\n",
    "    # print(article)\n",
    "    \n",
    "\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple today released ios ipados minor bug fix ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>expected apple rolling ios iphone users update...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple wednesday released ios ipados bug fixes ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iphone models emergency sos via satellite feat...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple released ios ipados iphone ipad download...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>smu topped houston saturday highest scoring re...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>smu quarterback tanner mordecai tossed nine to...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>smu houston offenses unstoppable saturday ap w...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>evanston ryan day reasonable explanation took ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>subscription supports investigative reporting ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article       genre\n",
       "0    apple today released ios ipados minor bug fix ...  technology\n",
       "1    expected apple rolling ios iphone users update...  technology\n",
       "2    apple wednesday released ios ipados bug fixes ...  technology\n",
       "3    iphone models emergency sos via satellite feat...  technology\n",
       "4    apple released ios ipados iphone ipad download...  technology\n",
       "..                                                 ...         ...\n",
       "195  smu topped houston saturday highest scoring re...      sports\n",
       "196  smu quarterback tanner mordecai tossed nine to...      sports\n",
       "197  smu houston offenses unstoppable saturday ap w...      sports\n",
       "198  evanston ryan day reasonable explanation took ...      sports\n",
       "199  subscription supports investigative reporting ...      sports\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"articles/technology/training\")\n",
    "\n",
    "# file2read = open(\"TrTechnologyArticle\" + str(6) +\n",
    "#                     \".txt\", 'r').read()\n",
    "\n",
    "# cleanArticle(file2read)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "articles = []\n",
    "genres = []\n",
    "item = 1\n",
    "\n",
    "\n",
    "while(item <= 100):\n",
    "    file2read = open(\"TrTechnologyArticle\" + str(item) +\n",
    "                     \".txt\", 'r').read()\n",
    "    file2read = cleanArticle(file2read)\n",
    "    articles.append(file2read)\n",
    "    genres.append(\"technology\")\n",
    "    item += 1\n",
    "\n",
    "item = 1\n",
    "\n",
    "os.chdir(\"../../sports/training\")\n",
    "\n",
    "while(item <= 100):\n",
    "    file2read = open(\"TrSportsArticle\" + str(item) +\n",
    "                     \".txt\", 'r').read().replace(\"\\n\", \"\")\n",
    "    file2read = cleanArticle(file2read)\n",
    "    articles.append(file2read)\n",
    "    genres.append(\"sports\")\n",
    "    item += 1 \n",
    "\n",
    "\n",
    "trainingData = {'article':  articles,\n",
    "                'genre': genres\n",
    "                }\n",
    "\n",
    "# print(articles[2])\n",
    "\n",
    "os.chdir(\"../../../\")\n",
    "\n",
    "\n",
    "trainingData = pd.DataFrame(trainingData)\n",
    "trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbs essentials created independently cbs news ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update wed nov gmt appearing pegi website last...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>publisher devolver digital developer daniel mu...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finally allowing posting last year instagram c...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>since instagram introduced website let users a...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>houston human nature amped maybe game extra bu...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>let get philadelphia eagles links predicting n...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>jesse mendez breakout performance first colleg...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>twitter instagram facebook order ohio state ti...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ccole mattin sam janicki michigan crowned four...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article       genre\n",
       "0    cbs essentials created independently cbs news ...  technology\n",
       "1    update wed nov gmt appearing pegi website last...  technology\n",
       "2    publisher devolver digital developer daniel mu...  technology\n",
       "3    finally allowing posting last year instagram c...  technology\n",
       "4    since instagram introduced website let users a...  technology\n",
       "..                                                 ...         ...\n",
       "195  houston human nature amped maybe game extra bu...      sports\n",
       "196  let get philadelphia eagles links predicting n...      sports\n",
       "197  jesse mendez breakout performance first colleg...      sports\n",
       "198  twitter instagram facebook order ohio state ti...      sports\n",
       "199  ccole mattin sam janicki michigan crowned four...      sports\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"articles/technology/testing\")\n",
    "temp = os.getcwd()\n",
    "\n",
    "\n",
    "articles = []\n",
    "genres = []\n",
    "item = 101\n",
    "\n",
    "\n",
    "os.getcwd\n",
    "\n",
    "\n",
    "while(item >= 101 and item <=200):\n",
    "    file2read = open(\"TeTechnologyArticle\" + str(item) +\n",
    "                     \".txt\", 'r').read()\n",
    "    file2read = cleanArticle(file2read)\n",
    "    articles.append(file2read)\n",
    "    genres.append(\"technology\")\n",
    "    item += 1\n",
    "\n",
    "item = 101\n",
    "\n",
    "os.chdir(\"../../sports/testing\")\n",
    "\n",
    "while(item >= 101 and item <=200):\n",
    "    file2read = open(\"TeSportsArticle\" + str(item) +\n",
    "                     \".txt\", 'r').read()\n",
    "    file2read = cleanArticle(file2read)\n",
    "    articles.append(file2read)\n",
    "    genres.append(\"sports\")\n",
    "    item += 1\n",
    "\n",
    "\n",
    "testingData = {'article':  articles,\n",
    "                'genre': genres\n",
    "                }\n",
    "\n",
    "# print(articles[2])\n",
    "\n",
    "os.chdir(\"../../../\")\n",
    "\n",
    "\n",
    "testingData = pd.DataFrame(testingData)\n",
    "testingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbs essentials created independently cbs news ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update wed nov gmt appearing pegi website last...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>publisher devolver digital developer daniel mu...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finally allowing posting last year instagram c...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>since instagram introduced website let users a...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>houston human nature amped maybe game extra bu...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>let get philadelphia eagles links predicting n...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>jesse mendez breakout performance first colleg...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>twitter instagram facebook order ohio state ti...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ccole mattin sam janicki michigan crowned four...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article       genre\n",
       "0    cbs essentials created independently cbs news ...  technology\n",
       "1    update wed nov gmt appearing pegi website last...  technology\n",
       "2    publisher devolver digital developer daniel mu...  technology\n",
       "3    finally allowing posting last year instagram c...  technology\n",
       "4    since instagram introduced website let users a...  technology\n",
       "..                                                 ...         ...\n",
       "195  houston human nature amped maybe game extra bu...      sports\n",
       "196  let get philadelphia eagles links predicting n...      sports\n",
       "197  jesse mendez breakout performance first colleg...      sports\n",
       "198  twitter instagram facebook order ohio state ti...      sports\n",
       "199  ccole mattin sam janicki michigan crowned four...      sports\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make email values lower case\n",
    "testingData[\"article\"] = testingData[\"article\"].apply(lambda str : str.lower())\n",
    "trainingData[\"article\"] = trainingData[\"article\"].apply(lambda str : str.lower())  \n",
    "# trainingData\n",
    "testingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#get probability of spam and not spam\n",
    "sum_s = 0\n",
    "sum_t = 0\n",
    "for i in trainingData[\"genre\"]:\n",
    "    if i == \"sports\":\n",
    "        sum_s += 1\n",
    "    elif i == \"technology\":\n",
    "        sum_t += 1\n",
    "        \n",
    "prob_s = sum_s/len(trainingData)\n",
    "prob_t = sum_t/len(trainingData)\n",
    "\n",
    "print(prob_s)\n",
    "print(prob_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>genre</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple today released ios ipados minor bug fix ...</td>\n",
       "      <td>technology</td>\n",
       "      <td>{'apple': 3, 'today': 1, 'released': 1, 'ios':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>expected apple rolling ios iphone users update...</td>\n",
       "      <td>technology</td>\n",
       "      <td>{'expected': 2, 'apple': 8, 'rolling': 3, 'ios...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple wednesday released ios ipados bug fixes ...</td>\n",
       "      <td>technology</td>\n",
       "      <td>{'apple': 3, 'wednesday': 1, 'released': 2, 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iphone models emergency sos via satellite feat...</td>\n",
       "      <td>technology</td>\n",
       "      <td>{'iphone': 3, 'models': 2, 'emergency': 3, 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple released ios ipados iphone ipad download...</td>\n",
       "      <td>technology</td>\n",
       "      <td>{'apple': 4, 'released': 2, 'ios': 6, 'ipados'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>smu topped houston saturday highest scoring re...</td>\n",
       "      <td>sports</td>\n",
       "      <td>{'smu': 4, 'topped': 1, 'houston': 5, 'saturda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>smu quarterback tanner mordecai tossed nine to...</td>\n",
       "      <td>sports</td>\n",
       "      <td>{'smu': 1, 'quarterback': 1, 'tanner': 1, 'mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>smu houston offenses unstoppable saturday ap w...</td>\n",
       "      <td>sports</td>\n",
       "      <td>{'smu': 5, 'houston': 2, 'offenses': 1, 'unsto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>evanston ryan day reasonable explanation took ...</td>\n",
       "      <td>sports</td>\n",
       "      <td>{'evanston': 1, 'ryan': 1, 'day': 1, 'reasonab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>subscription supports investigative reporting ...</td>\n",
       "      <td>sports</td>\n",
       "      <td>{'subscription': 1, 'supports': 1, 'investigat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article       genre  \\\n",
       "0    apple today released ios ipados minor bug fix ...  technology   \n",
       "1    expected apple rolling ios iphone users update...  technology   \n",
       "2    apple wednesday released ios ipados bug fixes ...  technology   \n",
       "3    iphone models emergency sos via satellite feat...  technology   \n",
       "4    apple released ios ipados iphone ipad download...  technology   \n",
       "..                                                 ...         ...   \n",
       "195  smu topped houston saturday highest scoring re...      sports   \n",
       "196  smu quarterback tanner mordecai tossed nine to...      sports   \n",
       "197  smu houston offenses unstoppable saturday ap w...      sports   \n",
       "198  evanston ryan day reasonable explanation took ...      sports   \n",
       "199  subscription supports investigative reporting ...      sports   \n",
       "\n",
       "                                                   bow  \n",
       "0    {'apple': 3, 'today': 1, 'released': 1, 'ios':...  \n",
       "1    {'expected': 2, 'apple': 8, 'rolling': 3, 'ios...  \n",
       "2    {'apple': 3, 'wednesday': 1, 'released': 2, 'i...  \n",
       "3    {'iphone': 3, 'models': 2, 'emergency': 3, 'so...  \n",
       "4    {'apple': 4, 'released': 2, 'ios': 6, 'ipados'...  \n",
       "..                                                 ...  \n",
       "195  {'smu': 4, 'topped': 1, 'houston': 5, 'saturda...  \n",
       "196  {'smu': 1, 'quarterback': 1, 'tanner': 1, 'mor...  \n",
       "197  {'smu': 5, 'houston': 2, 'offenses': 1, 'unsto...  \n",
       "198  {'evanston': 1, 'ryan': 1, 'day': 1, 'reasonab...  \n",
       "199  {'subscription': 1, 'supports': 1, 'investigat...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData[\"bow\"] = trainingData[\"article\"].str.split().apply(Counter) # split string into the bag of words an then count them\n",
    "trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_bow_s = {}\n",
    "sum_bow_t = {}\n",
    "i=0\n",
    "\n",
    "for bow in trainingData[\"bow\"]: #value of bag of word in each article\n",
    "    for key in bow: #value of word in each bag of word\n",
    "        if trainingData[\"genre\"][i] == \"sports\": #in case of spam\n",
    "            if key in sum_bow_s: #if the word exists in sum of bows\n",
    "                # print(\"sum of bow in if: \", sum_bow_s)\n",
    "                sum_bow_s[key] += bow[key]\n",
    "                # print(\"sum of bow in if: \", sum_bow_s)\n",
    "\n",
    "            else:\n",
    "                # print(\"key in else: \",key)\n",
    "                # print('bow of key', bow[key])\n",
    "                sum_bow_s[key] = bow[key]\n",
    "                # print(\"sum of bow in else: \", sum_bow_s)\n",
    "        else:\n",
    "            if key in sum_bow_t:\n",
    "                sum_bow_t[key] +=bow[key]\n",
    "            else:\n",
    "                sum_bow_t[key] = bow[key]\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print(sum_bow_s)\n",
    "print(sum_bow_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42133\n",
      "30749\n"
     ]
    }
   ],
   "source": [
    "#calculates total number of words in each dictionary\n",
    "term_occurences_s = 0\n",
    "term_occurences_t = 0\n",
    "for key in sum_bow_s:\n",
    "    term_occurences_s += sum_bow_s[key]\n",
    "for key in sum_bow_t:    \n",
    "    term_occurences_t += sum_bow_t[key]\n",
    "print(term_occurences_s)\n",
    "print(term_occurences_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11153"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate number of unique words in total\n",
    "temp = []\n",
    "unique_term = 0\n",
    "for bow in trainingData[\"bow\"]:\n",
    "    for key in bow:\n",
    "        if key not in temp:\n",
    "            unique_term += 1\n",
    "            temp.append(key)\n",
    "# it goes to every single word in BoW and if it is not stored in the array store it and increase unique_term number by 1\n",
    "unique_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1.002277654290497,\n",
       " 'two': 1.0044867045360995,\n",
       " 'update': 1.0015504514146154,\n",
       " 'going': 1.0016602178864467,\n",
       " 'users': 1.0011388271452484,\n",
       " 'see': 1.0014132433248264,\n",
       " 'app': 1.0015641722235944,\n",
       " 'new': 1.0047885623336352,\n",
       " 'home': 1.0013309184709531,\n",
       " 'last': 1.0023736999533492,\n",
       " 'also': 1.0033615981998298,\n",
       " 'well': 1.0016739386954254,\n",
       " 'performance': 1.0011799895721851,\n",
       " 'may': 1.0012897560440164,\n",
       " 'next': 1.0019483548750034,\n",
       " 'us': 1.0010153398644384,\n",
       " 'know': 1.0010290606734173,\n",
       " 'made': 1.0017288219313412,\n",
       " 'would': 1.002016958919898,\n",
       " 'like': 1.0035536895255344,\n",
       " 'right': 1.0015504514146154,\n",
       " 'need': 1.001056502291375,\n",
       " 'open': 1.0012897560440164,\n",
       " 'system': 1.001070223100354,\n",
       " 'world': 1.0026892785598638,\n",
       " 'time': 1.0034027606267666,\n",
       " 'go': 1.00174254274032,\n",
       " 'take': 1.0012897560440164,\n",
       " 'best': 1.0019620756839824,\n",
       " 'run': 1.0021953294366235,\n",
       " 'including': 1.0010976647183119,\n",
       " 'make': 1.0019895173019402,\n",
       " 'even': 1.0019757964929612,\n",
       " 'first': 1.0060920391866304,\n",
       " 'drive': 1.0011799895721851,\n",
       " 'said': 1.004143684311627,\n",
       " 'things': 1.0013583600889109,\n",
       " 'big': 1.0016876595044044,\n",
       " 'three': 1.002524628852117,\n",
       " 'could': 1.001893471639088,\n",
       " 'used': 1.001070223100354,\n",
       " 'windows': 1.0015367306056364,\n",
       " 'end': 1.0018385884031722,\n",
       " 'people': 1.0010016190554596,\n",
       " 'high': 1.0011251063362696,\n",
       " 'running': 1.0013995225158476,\n",
       " 'november': 1.0012897560440164,\n",
       " 'one': 1.0046376334348672,\n",
       " 'early': 1.0013034768529951,\n",
       " 'third': 1.0018523092121512,\n",
       " 'year': 1.0020306797288767,\n",
       " 'another': 1.0014269641338054,\n",
       " 'microsoft': 1.0019620756839824,\n",
       " 'games': 1.0028950906945473,\n",
       " 'point': 1.0011388271452484,\n",
       " 'game': 1.0103180483521308,\n",
       " 'pass': 1.0017288219313412,\n",
       " 'players': 1.0021267253917292,\n",
       " 'nintendo': 1.0011388271452484,\n",
       " 'since': 1.0016464970774677,\n",
       " 'back': 1.0027853242227163,\n",
       " 'times': 1.0010153398644384,\n",
       " 'better': 1.0013583600889109,\n",
       " 'many': 1.0015092889876787,\n",
       " 'still': 1.0017151011223622,\n",
       " 'years': 1.0011251063362696,\n",
       " 'get': 1.002936253121484,\n",
       " 'team': 1.0036771768063446,\n",
       " 'lot': 1.0010016190554596,\n",
       " 'day': 1.0010976647183119,\n",
       " 'win': 1.0033890398177876,\n",
       " 'field': 1.0018385884031722,\n",
       " 'good': 1.0017699843582777,\n",
       " 'way': 1.0017151011223622,\n",
       " 'much': 1.0014132433248264,\n",
       " 'lead': 1.0014406849427842,\n",
       " 'league': 1.0015504514146154,\n",
       " 'season': 1.0031420652561676,\n",
       " 'start': 1.0012074311901429,\n",
       " 'series': 1.0027304409868005,\n",
       " 'left': 1.001468126560742,\n",
       " 'play': 1.0031695068741253,\n",
       " 'state': 1.0043357756373317,\n",
       " 'four': 1.0014544057517631,\n",
       " 'think': 1.0011937103811641,\n",
       " 'second': 1.002936253121484,\n",
       " 'got': 1.0019757964929612,\n",
       " 'defense': 1.001632776268489,\n",
       " 'friday': 1.0010016190554596,\n",
       " 'week': 1.0024560248072227,\n",
       " 'line': 1.0013034768529951,\n",
       " 'power': 1.001070223100354,\n",
       " 'sonic': 1.0014132433248264,\n",
       " 'half': 1.0017151011223622,\n",
       " 'gpu': 1.0010153398644384,\n",
       " 'came': 1.0013171976619741,\n",
       " 'loss': 1.0017699843582777,\n",
       " 'goal': 1.0011937103811641,\n",
       " 'ball': 1.0015641722235944,\n",
       " 'max': 1.0015230097966576,\n",
       " 'five': 1.0011388271452484,\n",
       " 'quarter': 1.0017699843582777,\n",
       " 'data': 1.0013583600889109,\n",
       " 'top': 1.0012211519991219,\n",
       " 'fourth': 1.0012897560440164,\n",
       " 'teams': 1.0011799895721851,\n",
       " 'intel': 1.0019209132570457,\n",
       " 'saturday': 1.0020718421558135,\n",
       " 'night': 1.0013720808978896,\n",
       " 'astros': 1.00186603002113,\n",
       " 'offense': 1.0012623144260586,\n",
       " 'yards': 1.0042397299744792,\n",
       " 'touchdown': 1.0024285831892648,\n",
       " 'football': 1.0015367306056364,\n",
       " 'tigers': 1.0011251063362696,\n",
       " 'coach': 1.0011799895721851,\n",
       " 'yard': 1.0028264866496528,\n",
       " 'quarterback': 1.0012760352350374,\n",
       " 'mississippi': 1.0010290606734173,\n",
       " 'auburn': 1.0016739386954254,\n",
       " 'clemson': 1.001070223100354,\n",
       " 'touchdowns': 1.0012348728081009,\n",
       " 'ucla': 1.0010839439093329,\n",
       " 'republic': 1.0015092889876787}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_bow = {} \n",
    "term_occurences = 0 #number of words occured in total in sport and technology\n",
    "for bow in trainingData[\"bow\"]:\n",
    "    for key in bow:\n",
    "        if key in sum_bow:\n",
    "            sum_bow[key] += bow[key]\n",
    "        else:\n",
    "            sum_bow[key] = bow[key]\n",
    "        term_occurences += bow[key]\n",
    "\n",
    "# print(sum_bow)\n",
    "\n",
    "\n",
    "prob_bow = {}\n",
    "for key in sum_bow:\n",
    "    # if((sum_bow[key]/(term_occurences)) >0.001 ):\n",
    "    prob_bow[key] = (sum_bow[key]/(term_occurences)) +1 #probability of word in general for sport and technology\n",
    "\n",
    "prob_bow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.589418191448325e-09\n",
      "2.816950601363801e-08\n"
     ]
    }
   ],
   "source": [
    "def split(words): #split string into array of words\n",
    "    return words.split()\n",
    "\n",
    "\n",
    "def lower(words): #lowercase the letters in the string\n",
    "    return words.lower()\n",
    "\n",
    "def probSports(email): #calculate the probability of spam of the string\n",
    "    email = split(lower(email))\n",
    "    likelihood = 1\n",
    "    evidence = 1\n",
    "    for term in email:\n",
    "        if term in prob_bow: #check if word has probability value so that it won't throw error for unrecognised words\n",
    "            if term in sum_bow_s:\n",
    "                likelihood *= (sum_bow_s[term]+1)/(term_occurences_s+unique_term) #naive beyes formula \n",
    "            else:\n",
    "                likelihood *= 1/(term_occurences_s+unique_term)\n",
    "\n",
    "            evidence *= prob_bow[term]\n",
    "            # print(evidence)\n",
    "\n",
    "    likelihood_prior = likelihood*prob_s\n",
    "    posterior = likelihood_prior/evidence\n",
    "    return posterior\n",
    "\n",
    "def probTech(email): #calculate the probability of not spam of the string\n",
    "    email = split(lower(email))\n",
    "    likelihood = 1\n",
    "    evidence = 1\n",
    "    for term in email:\n",
    "        if term in prob_bow:\n",
    "            if term in sum_bow_t:\n",
    "                likelihood *= (sum_bow_t[term]+1)/(term_occurences_t+unique_term) \n",
    "            else:\n",
    "                likelihood *= 1/(term_occurences_t+unique_term)\n",
    "                \n",
    "            evidence *= prob_bow[term]\n",
    "            # print(evidence)\n",
    "\n",
    "    likelihood_prior = likelihood*prob_t\n",
    "    \n",
    "    posterior = float(likelihood_prior)/evidence\n",
    "    return posterior\n",
    "\n",
    "\n",
    "print(probSports(\"sports NFL Rugby footbal nfl, tech , 23412 apple apple\"))\n",
    "print(probTech(\"apple, sports apple apple apple\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.110288575339775e-149\n"
     ]
    }
   ],
   "source": [
    "testArticle = testingData[\"article\"][15]\n",
    "print(probSports(testArticle))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb4d557434260ebf075e28dd60749004257cbe2841be8fafa16b5a0ada42e623"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
